{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMoVEi4f5du5j7sA5GAL7/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya161205/codoc/blob/main/CODOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjmo6MBsrE3R",
        "outputId": "28e65a3d-a0ab-4408-f997-610ac36a29ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.12/dist-packages (3.1.45)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install GitPython\n",
        "\n",
        "import os\n",
        "import ast\n",
        "from git import Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **First lets clone the repo to be documented**"
      ],
      "metadata": {
        "id": "tA1uBxCTK4CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from git import Repo\n",
        "import shutil\n",
        "\n",
        "repo_url = \"https://github.com/aditya161205/mock\"\n",
        "local_dir = \"dir\"\n",
        "\n",
        "if os.path.exists(local_dir) and os.path.isdir(local_dir):\n",
        "    shutil.rmtree(local_dir)\n",
        "\n",
        "repo = Repo.clone_from(repo_url, local_dir)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OtQXN3oXrTUx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = []"
      ],
      "metadata": {
        "id": "Djsy1SrUChKh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parsing the files in the repo**"
      ],
      "metadata": {
        "id": "FqBWnGLBK9sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def parsing(file_path):\n",
        "    file_info = {\n",
        "        \"file\": file_path,\n",
        "        \"imports\": [],\n",
        "        \"functions\": [],\n",
        "        \"classes\": []\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            content = file.read()\n",
        "        tree = ast.parse(content)\n",
        "\n",
        "        for node in ast.walk(tree):\n",
        "            # --- Functions ---\n",
        "            if isinstance(node, ast.FunctionDef):\n",
        "                func_code = ast.get_source_segment(content, node)\n",
        "                func = {\n",
        "                    \"name\": node.name,\n",
        "                    \"doc\": ast.get_docstring(node) or \"\",\n",
        "                    \"args\": [arg.arg for arg in node.args.args],\n",
        "                    \"code\": func_code or \"\"\n",
        "                }\n",
        "                file_info[\"functions\"].append(func)\n",
        "\n",
        "            # --- Classes ---\n",
        "            elif isinstance(node, ast.ClassDef):\n",
        "                methods_list = []\n",
        "                for method in node.body:\n",
        "                    if isinstance(method, ast.FunctionDef):\n",
        "                        method_code = ast.get_source_segment(content, method)\n",
        "                        methods_list.append({\n",
        "                            \"name\": method.name,\n",
        "                            \"doc\": ast.get_docstring(method) or \"\",\n",
        "                            \"args\": [arg.arg for arg in method.args.args],\n",
        "                            \"code\": method_code or \"\"\n",
        "                        })\n",
        "                cls = {\n",
        "                    \"name\": node.name,\n",
        "                    \"doc\": ast.get_docstring(node) or \"\",\n",
        "                    \"methods\": methods_list\n",
        "                }\n",
        "                file_info[\"classes\"].append(cls)\n",
        "\n",
        "            # --- Imports ---\n",
        "            elif isinstance(node, ast.Import):\n",
        "                for alias in node.names:\n",
        "                    file_info[\"imports\"].append(alias.name)\n",
        "            elif isinstance(node, ast.ImportFrom):\n",
        "                if node.module:\n",
        "                    file_info[\"imports\"].append(node.module)\n",
        "\n",
        "        return file_info\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(f\"SyntaxError parsing {file_path}: {e}\")\n",
        "        return file_info\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {file_path}: {e}\")\n",
        "        return file_info"
      ],
      "metadata": {
        "id": "patIuF_bryis"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Walk through repo ===\n",
        "for root, dirs, files in os.walk(local_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".py\"):\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_data = parsing(file_path)\n",
        "            parsed_data.append(file_data)\n"
      ],
      "metadata": {
        "id": "SY_JXAt_skbr"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Output preview ===\n",
        "import json\n",
        "print(json.dumps(parsed_data, indent=2))"
      ],
      "metadata": {
        "id": "vntfGjPmu0BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37c0c7b-1e13-46a9-bc5a-cac0d380397c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"file\": \"dir/ex.py\",\n",
            "    \"imports\": [],\n",
            "    \"functions\": [\n",
            "      {\n",
            "        \"name\": \"add_numbers\",\n",
            "        \"doc\": \"Return the sum of two numbers.\",\n",
            "        \"args\": [\n",
            "          \"a\",\n",
            "          \"b\"\n",
            "        ],\n",
            "        \"code\": \"def add_numbers(a, b):\\n    \\\"\\\"\\\"Return the sum of two numbers.\\\"\\\"\\\"\\n    return a + b\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"multiply_numbers\",\n",
            "        \"doc\": \"Return the product of two numbers.\",\n",
            "        \"args\": [\n",
            "          \"a\",\n",
            "          \"b\"\n",
            "        ],\n",
            "        \"code\": \"def multiply_numbers(a, b):\\n    \\\"\\\"\\\"Return the product of two numbers.\\\"\\\"\\\"\\n    return a * b\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"is_even\",\n",
            "        \"doc\": \"Check if a number is even.\",\n",
            "        \"args\": [\n",
            "          \"number\"\n",
            "        ],\n",
            "        \"code\": \"def is_even(number):\\n    \\\"\\\"\\\"Check if a number is even.\\\"\\\"\\\"\\n    return number % 2 == 0\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"greet\",\n",
            "        \"doc\": \"Return a greeting message.\",\n",
            "        \"args\": [\n",
            "          \"name\"\n",
            "        ],\n",
            "        \"code\": \"def greet(name):\\n    \\\"\\\"\\\"Return a greeting message.\\\"\\\"\\\"\\n    return f\\\"Hello, {name}!\\\"\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"__init__\",\n",
            "        \"doc\": \"\",\n",
            "        \"args\": [\n",
            "          \"self\",\n",
            "          \"value\"\n",
            "        ],\n",
            "        \"code\": \"def __init__(self, value=0):\\n        self.value = value\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"add\",\n",
            "        \"doc\": \"\",\n",
            "        \"args\": [\n",
            "          \"self\",\n",
            "          \"number\"\n",
            "        ],\n",
            "        \"code\": \"def add(self, number):\\n        self.value = add_numbers(self.value, number)\\n        return self.value\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"multiply\",\n",
            "        \"doc\": \"\",\n",
            "        \"args\": [\n",
            "          \"self\",\n",
            "          \"number\"\n",
            "        ],\n",
            "        \"code\": \"def multiply(self, number):\\n        self.value = multiply_numbers(self.value, number)\\n        return self.value\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"__init__\",\n",
            "        \"doc\": \"\",\n",
            "        \"args\": [\n",
            "          \"self\",\n",
            "          \"name\",\n",
            "          \"age\"\n",
            "        ],\n",
            "        \"code\": \"def __init__(self, name, age):\\n        self.name = name\\n        self.age = age\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"introduce\",\n",
            "        \"doc\": \"\",\n",
            "        \"args\": [\n",
            "          \"self\"\n",
            "        ],\n",
            "        \"code\": \"def introduce(self):\\n        return greet(self.name) + f\\\" I am {self.age} years old.\\\"\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"is_adult\",\n",
            "        \"doc\": \"\",\n",
            "        \"args\": [\n",
            "          \"self\"\n",
            "        ],\n",
            "        \"code\": \"def is_adult(self):\\n        return self.age >= 18\"\n",
            "      }\n",
            "    ],\n",
            "    \"classes\": [\n",
            "      {\n",
            "        \"name\": \"Calculator\",\n",
            "        \"doc\": \"A simple calculator that uses utility functions.\",\n",
            "        \"methods\": [\n",
            "          {\n",
            "            \"name\": \"__init__\",\n",
            "            \"doc\": \"\",\n",
            "            \"args\": [\n",
            "              \"self\",\n",
            "              \"value\"\n",
            "            ],\n",
            "            \"code\": \"def __init__(self, value=0):\\n        self.value = value\"\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"add\",\n",
            "            \"doc\": \"\",\n",
            "            \"args\": [\n",
            "              \"self\",\n",
            "              \"number\"\n",
            "            ],\n",
            "            \"code\": \"def add(self, number):\\n        self.value = add_numbers(self.value, number)\\n        return self.value\"\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"multiply\",\n",
            "            \"doc\": \"\",\n",
            "            \"args\": [\n",
            "              \"self\",\n",
            "              \"number\"\n",
            "            ],\n",
            "            \"code\": \"def multiply(self, number):\\n        self.value = multiply_numbers(self.value, number)\\n        return self.value\"\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Person\",\n",
            "        \"doc\": \"Represents a person with a name and age.\",\n",
            "        \"methods\": [\n",
            "          {\n",
            "            \"name\": \"__init__\",\n",
            "            \"doc\": \"\",\n",
            "            \"args\": [\n",
            "              \"self\",\n",
            "              \"name\",\n",
            "              \"age\"\n",
            "            ],\n",
            "            \"code\": \"def __init__(self, name, age):\\n        self.name = name\\n        self.age = age\"\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"introduce\",\n",
            "            \"doc\": \"\",\n",
            "            \"args\": [\n",
            "              \"self\"\n",
            "            ],\n",
            "            \"code\": \"def introduce(self):\\n        return greet(self.name) + f\\\" I am {self.age} years old.\\\"\"\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"is_adult\",\n",
            "            \"doc\": \"\",\n",
            "            \"args\": [\n",
            "              \"self\"\n",
            "            ],\n",
            "            \"code\": \"def is_adult(self):\\n        return self.age >= 18\"\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding schemantic meaning to functions and classes**"
      ],
      "metadata": {
        "id": "Qg_91FLvKr5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnhjXk2HQ2Wy",
        "outputId": "e57bb1f7-8d2d-4c12-a264-c231aba8bb69"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Lightweight, fast, and good for semantic search\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "UbsirzxNX7Iq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = []\n",
        "metadata = []\n",
        "\n",
        "for file_item in parsed_data:\n",
        "    # Functions\n",
        "    for func in file_item[\"functions\"]:\n",
        "        # --- CHANGE HERE ---\n",
        "        # Create a richer text document for embedding.\n",
        "        # This combines the most important semantic information.\n",
        "        args_str = \", \".join(func.get(\"args\", []))\n",
        "        docstring = func.get(\"doc\", \"This function has no docstring.\")\n",
        "\n",
        "        text_to_embed = (\n",
        "            f\"Function Name: {func['name']}\\n\"\n",
        "            f\"Signature: def {func['name']}({args_str}):\\n\"\n",
        "            f\"Docstring: {docstring}\"\n",
        "        )\n",
        "\n",
        "        # Encode this richer text instead of just the summary.\n",
        "        vector = embed_model.encode(text_to_embed)\n",
        "        embeddings.append(vector)\n",
        "\n",
        "        # The metadata can stay the same, as it holds the raw info.\n",
        "        metadata.append({\n",
        "            \"file\": file_item[\"file\"],\n",
        "            \"type\": \"function\",\n",
        "            \"name\": func[\"name\"],\n",
        "            \"args\": func.get(\"args\", []),\n",
        "            \"doc\": docstring, # Store the clean docstring\n",
        "            \"code\": func.get(\"code\", \"\")\n",
        "        })\n",
        "\n",
        "    # Classes\n",
        "    for cls in file_item[\"classes\"]:\n",
        "        # --- CHANGE HERE ---\n",
        "        # Do the same for classes\n",
        "        method_names = [m.get(\"name\", \"\") for m in cls.get(\"methods\", [])]\n",
        "        docstring = cls.get(\"doc\", \"This class has no docstring.\")\n",
        "\n",
        "        text_to_embed = (\n",
        "            f\"Class Name: {cls['name']}\\n\"\n",
        "            f\"Methods: {', '.join(method_names)}\\n\"\n",
        "            f\"Docstring: {docstring}\"\n",
        "        )\n",
        "\n",
        "        vector = embed_model.encode(text_to_embed)\n",
        "        embeddings.append(vector)\n",
        "\n",
        "        metadata.append({\n",
        "            \"file\": file_item[\"file\"],\n",
        "            \"type\": \"class\",\n",
        "            \"name\": cls[\"name\"],\n",
        "            \"doc\": docstring,\n",
        "            \"methods\": cls.get(\"methods\", []),\n",
        "            \"code\": \"\\n\".join([m.get(\"code\",\"\") for m in cls[\"methods\"]])\n",
        "        })\n",
        "\n",
        "embeddings = np.array(embeddings).astype(\"float32\")"
      ],
      "metadata": {
        "id": "e_xDCsdaX8lI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dimension = embeddings.shape[1]  # embedding size\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
        "index.add(embeddings)\n"
      ],
      "metadata": {
        "id": "r3r9FWN7YBkW"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "print(\"Loading Q&A model (Flan-T5)...\")\n",
        "# FIX: Load the correct model and tokenizer with consistent variable names\n",
        "qa_model_name = \"google/flan-t5-base\"\n",
        "qa_tokenizer = T5Tokenizer.from_pretrained(qa_model_name)\n",
        "qa_model = T5ForConditionalGeneration.from_pretrained(qa_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEPfVKOFZ90X",
        "outputId": "792e15c5-a744-4510-82b9-f836b2c23285"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Q&A model (Flan-T5)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumes you have loaded an instruction-tuned model like this:\n",
        "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "# qa_model_name = \"google/flan-t5-base\"\n",
        "# qa_tokenizer = T5Tokenizer.from_pretrained(qa_model_name)\n",
        "# qa_model = T5ForConditionalGeneration.from_pretrained(qa_model_name)\n",
        "\n",
        "def rag_query(query, top_k=5, max_context_length=1024):\n",
        "    # --- 1. Embed query and retrieve documents (same as before) ---\n",
        "    query_vector = embed_model.encode([query]).astype(\"float32\")\n",
        "\n",
        "    distances, indices = index.search(query_vector, top_k)\n",
        "    retrieved_items = [metadata[idx] for idx in indices[0]]\n",
        "\n",
        "    # --- 2. CHANGE: Build a cleaner, more structured context ---\n",
        "    # This format is easier for the LLM to understand than raw code.\n",
        "    context_pieces = []\n",
        "    for item in retrieved_items:\n",
        "        args_str = \", \".join(item.get(\"args\", []))\n",
        "        piece = (\n",
        "            f\"File Path: {item['file']}\\n\"\n",
        "            f\"Type: {item['type'].title()}\\n\"\n",
        "            f\"Name: {item['name']}\\n\"\n",
        "            f\"Signature: def {item['name']}({args_str}):\\n\"\n",
        "            f\"Docstring: {item['doc']}\"\n",
        "        )\n",
        "        context_pieces.append(piece)\n",
        "\n",
        "    context = \"\\n\\n---\\n\\n\".join(context_pieces)\n",
        "\n",
        "    # Truncate if the combined context is too long\n",
        "    context = context[:max_context_length]\n",
        "\n",
        "    # --- 3. CHANGE: Use a more robust prompt template ---\n",
        "    # This guides the model to answer accurately based only on the context.\n",
        "    prompt_template = \"\"\"\n",
        "Use the following context from a Python codebase to answer the question.\n",
        "If the context does not contain the information needed to answer the question, state that you cannot find the answer in the provided documentation.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    prompt = prompt_template.format(context=context, question=query)\n",
        "\n",
        "    # --- 4. CHANGE: Use the dedicated Q&A model for generation ---\n",
        "    inputs = qa_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "\n",
        "    output_ids = qa_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=256,         # Increased max_length for more detailed answers\n",
        "        num_beams=5,            # Increased beams for better quality generation\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    answer = qa_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer, retrieved_items"
      ],
      "metadata": {
        "id": "yCS3gY49YOn8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = \"how to give a greet message?\"\n",
        "answer, retrieved = rag_query(query, top_k=3)\n",
        "\n",
        "print(\"===== RAG Answer =====\")\n",
        "print(answer)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(\"===== Retrieved Items =====\")\n",
        "for item in retrieved:\n",
        "    # FIX: Changed item['summary'] to item['doc'] to match the new metadata\n",
        "    print(f\"Type: {item['type'].title()}\\nName: {item['name']}\\nFile: {item['file']}\\nDocstring: {item['doc']}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7VzR40MZbca",
        "outputId": "d10252b3-fcf2-4388-b7f5-164ee79a15fe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== RAG Answer =====\n",
            "return a greeting message.\n",
            "--------------------------------------------------\n",
            "===== Retrieved Items =====\n",
            "Type: Function\n",
            "Name: greet\n",
            "File: dir/ex.py\n",
            "Docstring: Return a greeting message.\n",
            "--------------------------------------------------\n",
            "Type: Class\n",
            "Name: Person\n",
            "File: dir/ex.py\n",
            "Docstring: Represents a person with a name and age.\n",
            "--------------------------------------------------\n",
            "Type: Function\n",
            "Name: __init__\n",
            "File: dir/ex.py\n",
            "Docstring: \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x4fVpmeYaXvi"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}